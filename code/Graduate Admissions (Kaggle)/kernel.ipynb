{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sys\nimport os\n\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dd9dfdf447c629ce12b90b029ebb9cb8d15d73f1"
      },
      "cell_type": "code",
      "source": "df1 = pd.read_csv('../input/Admission_Predict.csv', sep='\\s*,\\s*', header=0, encoding='ascii', engine='python')\ndf2 = pd.read_csv('../input/Admission_Predict_Ver1.1.csv', sep='\\s*,\\s*', header=0, encoding='ascii', engine='python')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "df = df1\ndf.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "38f6b29c73e02587a348ba8ae64a0119f84671ed"
      },
      "cell_type": "code",
      "source": "df.describe()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6fa38c337c1e20855d92b086c5bd12f1004e15db"
      },
      "cell_type": "code",
      "source": "sns.set(style=\"white\")\n\nd = df\ncolumns = d.columns\n\n\n# Compute the correlation matrix\ncorr = d.corr()\n\n# Generate a mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(len(columns), len(columns)))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(h_neg=220, h_pos=10, s=75, l=50, sep=10, n=len(columns), center='light', as_cmap=True)\n\nax = sns.heatmap(\n    corr,\n    cmap=cmap,\n    center=0,\n    robust=True,\n    annot=True,\n    linewidths=0.5,\n    linecolor='white',\n    cbar=True,\n    cbar_kws={\"shrink\": .5},\n    square=True,\n    mask=mask)\n\nplt.yticks(rotation=0)\nplt.xticks(rotation=90)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ad58692fddf3f632987e9d542d2e094ac62f22da"
      },
      "cell_type": "code",
      "source": "g = sns.PairGrid(\n    d, \n    diag_sharey=True, \n    height=2.5, \n    aspect=1, \n    despine=True, \n    dropna=False)\ng = g.map(plt.scatter)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b2a727bafbf0f085ce4e888be221068ba4e62105"
      },
      "cell_type": "code",
      "source": "x_cols = [\"GRE Score\", \"TOEFL Score\", \"University Rating\", \"SOP\", \"LOR\", \"CGPA\", \"Research\"]\ny_col = \"Chance of Admit\"\n\n\n# for col in x_cols:\n#     df[col] = (df[col]-mean(df[col]))/(max(df[col] - min(df[col])))\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "600fcc97cbc51de7a2ec232867124740e4cac4e6"
      },
      "cell_type": "code",
      "source": "X = df[x_cols].values\ny = df[\"Chance of Admit\"].values\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "84a2250dd516a48f59bb1c39ad825724fa11420e"
      },
      "cell_type": "code",
      "source": "def print_performance(model, X_test, y_test):\n    preds = model.predict(X_test)\n\n    explained_variance_score = metrics.explained_variance_score(y_test, preds)\n    mean_absolute_error = metrics.mean_absolute_error(y_test, preds)\n    mean_squared_log_error = metrics.mean_squared_log_error(y_test, preds)\n    median_absolute_error = metrics.median_absolute_error(y_test, preds)\n    r2_score = metrics.r2_score(y_test, preds)\n\n    print(\"-\"*55)\n    print(\"Performance\")\n    print(\"-\"*55)\n    print(\"{} : {:.4f}\".format(\"Explained Variance Score \", explained_variance_score))\n    print(\"{} : {:.4f} \".format(\"Mean Absolute Error      \", mean_absolute_error))\n    print(\"{} : {:.4f} \".format(\"Mean Squared Error       \", mean_squared_log_error))\n    print(\"{} : {:.4f} \".format(\"Median Squared Error     \", median_absolute_error))\n    print(\"{} : {:.4f} \".format(\"R2 Score                 \", r2_score))\n    print(\"-\"*55)\n    print(\"\\n\\n\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "af8d44f166dd01ce366eda4730e7f17d1b0f953b"
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn import metrics \n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n\n\n# scaler = StandardScaler()\n\n# X_train_scaled = scaler.fit_transform(X_train)\n# X_test_scaled = scaler.transform(X_test)\n\n\n\nprint(\"Linear Regression\")\nmodel = LinearRegression(normalize=True)\nmodel.fit(X_train, y_train)\nprint_performance(model, X_test, y_test)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}